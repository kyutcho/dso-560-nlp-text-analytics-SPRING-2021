{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3\n",
    "\n",
    "Submit via Slack. Due on Tuesday, April 13th, 2020, 6:29pm PST. You may work with one other person.\n",
    "\n",
    "## TF-IDF\n",
    "\n",
    "You are an analyst working at McDonalds as a store operations analyst, and charged with identifying areas for improvement for each franchise. Several metropolitan locations have been suffering recently from lower reviews.\n",
    "\n",
    "Using the **mcdonalds-yelp-negative-reviews.csv** dataset, clean and parse the text reviews. Explain the decisions you make:\n",
    "- why remove/keep stopwords?\n",
    "- which stopwords to remove?\n",
    "- stemming versus lemmatization?\n",
    "- regex cleaning and substitution?\n",
    "- adding in custom stopwords?\n",
    "- what `n` for your `n-grams`?\n",
    "- which words to collocate together?\n",
    "\n",
    "Finally, generate a TF-IDF report that either **visualizes** or explains for a business (non-technical) stakeholder:\n",
    "* the features your analysis showed that customers cited as reasons for a poor review\n",
    "* the most common issues identified from your analysis that generated customer dissatisfaction.\n",
    "\n",
    "Explain to what degree the TF-IDF findings make sense - what are its limitations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "# import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mac_df = pd.read_csv(\"mcdonalds-yelp-negative-reviews.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>city</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>679455653</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>I'm not a huge mcds lover, but I've been to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>679455654</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Terrible customer service. I came in at 9:30pm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>679455655</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>First they \"lost\" my order, actually they gave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>679455656</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>I see I'm not the only one giving 1 star. Only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>679455657</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Well, it's McDonald's, so you know what the fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id     city                                             review\n",
       "0  679455653  Atlanta  I'm not a huge mcds lover, but I've been to be...\n",
       "1  679455654  Atlanta  Terrible customer service. I came in at 9:30pm...\n",
       "2  679455655  Atlanta  First they \"lost\" my order, actually they gave...\n",
       "3  679455656  Atlanta  I see I'm not the only one giving 1 star. Only...\n",
       "4  679455657  Atlanta  Well, it's McDonald's, so you know what the fo..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mac_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all lowercase\n",
    "mac_df[\"review\"] = mac_df[\"review\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\", binary=False)\n",
    "\n",
    "X = vectorizer.fit_transform(mac_df[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names()).T\n",
    "\n",
    "vec_df[\"num_count\"] = vec_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1516</th>\n",
       "      <th>1517</th>\n",
       "      <th>1518</th>\n",
       "      <th>1519</th>\n",
       "      <th>1520</th>\n",
       "      <th>1521</th>\n",
       "      <th>1522</th>\n",
       "      <th>1523</th>\n",
       "      <th>1524</th>\n",
       "      <th>num_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcdonald</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcdonalds</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>don</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ve</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fries</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordered</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coffee</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minutes</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 1526 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1  2  3  4  5  6  7  8  9  ...  1516  1517  1518  1519  1520  \\\n",
       "food       0  2  0  0  1  0  1  0  2  3  ...     1     0     0     0     0   \n",
       "mcdonald   0  0  0  0  2  1  1  0  0  1  ...     0     0     0     0     0   \n",
       "order      1  0  3  0  1  0  0  2  5  2  ...     3     2     1     1     0   \n",
       "drive      1  0  0  0  0  0  0  1  3  0  ...     0     2     0     0     0   \n",
       "just       0  1  1  0  0  0  0  0  0  1  ...     0     2     0     1     0   \n",
       "mcdonalds  0  1  0  0  0  0  0  0  4  0  ...     0     0     0     1     1   \n",
       "service    0  1  0  0  2  0  0  0  1  0  ...     0     0     0     0     0   \n",
       "time       1  0  0  0  1  0  0  1  1  2  ...     0     1     0     0     0   \n",
       "like       0  0  0  0  0  0  0  0  0  0  ...     1     0     0     0     0   \n",
       "place      0  0  0  0  1  0  0  0  0  1  ...     0     0     0     1     0   \n",
       "don        0  0  0  0  0  0  0  0  1  0  ...     1     0     0     0     0   \n",
       "location   0  0  0  0  2  0  2  0  0  0  ...     0     0     0     0     0   \n",
       "people     0  0  0  0  0  0  1  0  0  0  ...     0     0     0     0     0   \n",
       "ve         2  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
       "fries      0  0  0  0  0  0  0  0  0  1  ...     3     0     0     0     0   \n",
       "got        0  0  0  0  0  0  0  0  0  0  ...     1     1     0     0     0   \n",
       "good       0  0  0  0  0  0  0  0  0  0  ...     1     0     0     0     0   \n",
       "ordered    0  0  0  0  0  0  0  0  0  0  ...     2     2     0     0     0   \n",
       "coffee     0  0  0  0  0  0  0  2  0  0  ...     0     0     0     0     0   \n",
       "minutes    0  1  2  0  1  0  0  0  1  0  ...     1     0     0     0     0   \n",
       "\n",
       "           1521  1522  1523  1524  num_count  \n",
       "food          1     2     1     0        886  \n",
       "mcdonald      0     2     4     0        852  \n",
       "order         0     0     1     1        850  \n",
       "drive         0     0     0     0        693  \n",
       "just          0     1     3     2        596  \n",
       "mcdonalds     1     0     0     0        580  \n",
       "service       1     0     1     0        539  \n",
       "time          1     0     1     0        532  \n",
       "like          0     1     1     2        501  \n",
       "place         0     0     3     1        477  \n",
       "don           0     1     0     0        398  \n",
       "location      0     1     0     0        388  \n",
       "people        0     0     2     2        353  \n",
       "ve            1     0     1     0        325  \n",
       "fries         0     0     0     0        314  \n",
       "got           0     0     0     0        304  \n",
       "good          0     0     0     0        284  \n",
       "ordered       0     0     0     0        270  \n",
       "coffee        0     1     0     0        264  \n",
       "minutes       0     0     0     0        264  \n",
       "\n",
       "[20 rows x 1526 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_df.sort_values(\"num_count\", ascending=False)\\\n",
    "    .head(20)\n",
    "#     .drop(list(set(stopwords.words('english'))), errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the CountVectorizer, we can notice that many reviews contains \"food\", \"order\", \"service\", and \"time\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamburger Variation\n",
    "mac_df[\"review\"] = mac_df[\"review\"].str.replace(r\"\\w*\\s*burgers?\", \"burger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big Macs\n",
    "mac_df[\"review\"] = mac_df[\"review\"].str.replace(r\"big\\s*macs?\", \"burger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change types of burgers into burger to see how burgers served are reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# McDonald's\n",
    "mac_df[\"review\"] = mac_df[\"review\"].str.replace(r\"(?:\\bmcdonald(?:'?s?)?\\b)|(?:\\bmcds?\\b)\", \"mcdonald\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changed variations of McDonald's to mcdonald to add to stopwords later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punctuation Removal\n",
    "mac_df[\"review\"] = mac_df[\"review\"].str.replace(r\"[!|@|#|$|%|^|&|*|(|)|+|<|>|?|:|.|,|;|\\\"|\\'|\\\\]\", ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whitespace\n",
    "mac_df[\"review\"] = mac_df[\"review\"].str.replace(r\"\\s{2,}\", ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbers\n",
    "mac_df[\"review\"] = mac_df[\"review\"].str.replace(r\"\\d+\\S*\\d*\\w*\", \"NUM_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miscellaneous Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmer = PorterStemmer()\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stmmer_func(review):\n",
    "    tokens = [stemmer.stem(token) for token in review.split()]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason for choosing SnowballStemmer: Stemming is more appropriate than Lemmetization in our analysis because we want to search for keywords that causes the bad reviews. For example, we want to know if the order was the issue for the customer. And words \"ordered\" and \"order\" are likely to indicate that the review has something to do with order. Also, I chose SnowballStemmer over PorterStemmer because it is the improved version. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Add stopword to stopwords list\n",
    "stop_words.append(\"mcdonald\")\n",
    "stop_words = stop_words + [\".\",'.', \",\",\":\", \"''\", \"'s\", \"'\", \"``\", \"(\", \")\", \"-\", \"!\", \"*\", \"?\"]\n",
    "\n",
    "# Remove from stopwords list\n",
    "# stop_words.remove([\"because\", \"most\", \"only\"])\n",
    "\n",
    "for w in [\"because\", \"most\", \"only\"]:\n",
    "    stop_words.remove(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"because\" in stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I removed \"mcdonald\" as we already know the review is about mcdonald. \\\n",
    "I added because the word(s) after \"because\" signals what causes customers to leave a bad review. Same logic applies to \"most\" and \"only\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "# https://gaurav5430.medium.com/using-nltk-for-lemmatizing-sentences-c1bfff963258\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return lemmatized_sentence\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "mac_df[\"tokenized_words\"] = mac_df[\"review\"].apply(lemmatize_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove words in stopwords\n",
    "mac_df[\"tokenized_words\"] = mac_df[\"tokenized_words\"].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('drive', 'thru'),\n",
       " ('NUM_TOKEN', 'NUM_TOKEN'),\n",
       " ('NUM_TOKEN', 'minute'),\n",
       " ('fast', 'food'),\n",
       " ('get', 'order'),\n",
       " ('customer', 'service'),\n",
       " ('NUM_TOKEN', 'star'),\n",
       " ('take', 'order'),\n",
       " ('go', 'back'),\n",
       " ('wait', 'NUM_TOKEN'),\n",
       " ('NUM_TOKEN', 'time'),\n",
       " ('order', 'wrong'),\n",
       " ('ice', 'cream'),\n",
       " ('order', 'NUM_TOKEN'),\n",
       " ('bad', 'ever')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collocation_finder = BigramCollocationFinder.from_documents(mac_df[\"tokenized_words\"])\n",
    "measures = BigramAssocMeasures()\n",
    "\n",
    "collocation_finder.nbest(measures.raw_freq, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the words that tend to collocate together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(input=\"mcdonalds-yelp-negative-reviews.csv\",\n",
    "                         encoding=\"latin1\",\n",
    "                         lowercase=True,\n",
    "                         stop_words=stop_words,\n",
    "                         ngram_range=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(mac_df[\"review\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)\n",
    "terms = vectorizer.get_feature_names()\n",
    "tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tf_idf.sum(axis=1)\n",
    "score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "score.sort_values(by=\"score\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_token num_token num_token</th>\n",
       "      <td>3.603224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get order right</th>\n",
       "      <td>3.298009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_token minutes get</th>\n",
       "      <td>2.752656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waited num_token minutes</th>\n",
       "      <td>2.425034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went drive thru</th>\n",
       "      <td>2.403620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open num_token hours</th>\n",
       "      <td>2.209245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive thru num_token</th>\n",
       "      <td>2.204614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive thru window</th>\n",
       "      <td>2.191361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>took num_token minutes</th>\n",
       "      <td>2.122771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got order wrong</th>\n",
       "      <td>2.108171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waiting num_token minutes</th>\n",
       "      <td>2.094051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive thru line</th>\n",
       "      <td>1.924068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>every single time</th>\n",
       "      <td>1.744119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never get order</th>\n",
       "      <td>1.717983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst service ever</th>\n",
       "      <td>1.670446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  score\n",
       "num_token num_token num_token  3.603224\n",
       "get order right                3.298009\n",
       "num_token minutes get          2.752656\n",
       "waited num_token minutes       2.425034\n",
       "went drive thru                2.403620\n",
       "open num_token hours           2.209245\n",
       "drive thru num_token           2.204614\n",
       "drive thru window              2.191361\n",
       "took num_token minutes         2.122771\n",
       "got order wrong                2.108171\n",
       "waiting num_token minutes      2.094051\n",
       "drive thru line                1.924068\n",
       "every single time              1.744119\n",
       "never get order                1.717983\n",
       "worst service ever             1.670446"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n-gram justification: I tried bigram for the analysis, but most words with high scores are usually collocated words like drive thru and ice cream. And quadgram simply has too many words that it does not appear in top rows. That is why I chose trigram. I acknowledge treating collocated words into one word will improve the analysis much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the bad reviews are order related. Customers either did not get what they ordered or it took too long to get what they ordered, or even both. It seems like drive through and customer service need improvements as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is consistent with the CountVectorizer analysis above as words like order, service were frequent words. However, none of tokens with high TF-IDF scores are food related as opposed to what we have observed in CounterVectorizer. There may be many reasons for that, but my assumption is that food is weighted down as they appear in many reviews. Also, there might be many variations around the word food, and thus not show up as much as the single word \"food\" does.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Attribution (Feature Engineering and Regex Practice)\n",
    "\n",
    "Download the [dataset](https://dso-560-nlp-text-analytics.s3.amazonaws.com/truncated_catalog.csv) from the class S3 bucket (`dso560-nlp-text-analytics`).\n",
    "\n",
    "In preparation for the group project, our client company has provided a dataset of women's clothing products they are considering cataloging. \n",
    "\n",
    "1. Filter for only **women's clothing items**.\n",
    "\n",
    "2. For each clothing item:\n",
    "\n",
    "* Identify its **category**:\n",
    "```\n",
    "Bottom\n",
    "One Piece\n",
    "Shoe\n",
    "Handbag\n",
    "Scarf\n",
    "```\n",
    "* Identify its **color**:\n",
    "```\n",
    "Beige\n",
    "Black\n",
    "Blue\n",
    "Brown\n",
    "Burgundy\n",
    "Gold\n",
    "Gray\n",
    "Green\n",
    "Multi \n",
    "Navy\n",
    "Neutral\n",
    "Orange\n",
    "Pinks\n",
    "Purple\n",
    "Red\n",
    "Silver\n",
    "Teal\n",
    "White\n",
    "Yellow\n",
    "```\n",
    "\n",
    "Your output will be the same dataset, except with **3 additional fields**:\n",
    "* `is_womens_clothing`\n",
    "* `product_category`\n",
    "* `colors`\n",
    "\n",
    "`colors` should be a list of colors, since it is possible for a piece of clothing to have multiple colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_df = pd.read_csv(\"truncated_catalog.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = prod_df.columns.to_list()\n",
    "\n",
    "for col in cols:\n",
    "    prod_df[col] = prod_df[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Null Values\n",
    "prod_df.iloc[:, :7] = prod_df.iloc[:, :7].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>tsv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fila</td>\n",
       "      <td>original fitness sneakers</td>\n",
       "      <td>vintage fitness leather sneakers with logo pri...</td>\n",
       "      <td>themensstore/shoes/sneakers/lowtop</td>\n",
       "      <td>https://www.saksfifthavenue.com/fila-original-...</td>\n",
       "      <td>leather/synthetic upper\\nlace-up closure\\ntext...</td>\n",
       "      <td>'design':12 'fila':1a 'fit':3a,6 'leather':7 '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chanel</td>\n",
       "      <td>hat</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://www.saksfifthavenue.com/chanel-hat/pro...</td>\n",
       "      <td>wool tweed &amp; felt</td>\n",
       "      <td>'chanel':1a 'hat':2a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame</td>\n",
       "      <td>petit oval buckle belt</td>\n",
       "      <td>a timeless leather belt crafted from smooth co...</td>\n",
       "      <td>accessories</td>\n",
       "      <td>https://frame-store.com/products/petit-oval-bu...</td>\n",
       "      <td></td>\n",
       "      <td>'belt':5a,9 'buckl':4a,21 'cowhid':13 'craft':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    brand                       name  \\\n",
       "0    fila  original fitness sneakers   \n",
       "1  chanel                        hat   \n",
       "2   frame     petit oval buckle belt   \n",
       "\n",
       "                                         description  \\\n",
       "0  vintage fitness leather sneakers with logo pri...   \n",
       "1                                                      \n",
       "2  a timeless leather belt crafted from smooth co...   \n",
       "\n",
       "                       brand_category  \\\n",
       "0  themensstore/shoes/sneakers/lowtop   \n",
       "1                             unknown   \n",
       "2                         accessories   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://www.saksfifthavenue.com/fila-original-...   \n",
       "1  https://www.saksfifthavenue.com/chanel-hat/pro...   \n",
       "2  https://frame-store.com/products/petit-oval-bu...   \n",
       "\n",
       "                                             details  \\\n",
       "0  leather/synthetic upper\\nlace-up closure\\ntext...   \n",
       "1                                  wool tweed & felt   \n",
       "2                                                      \n",
       "\n",
       "                                                 tsv  \n",
       "0  'design':12 'fila':1a 'fit':3a,6 'leather':7 '...  \n",
       "1                               'chanel':1a 'hat':2a  \n",
       "2  'belt':5a,9 'buckl':4a,21 'cowhid':13 'craft':...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is_womens_clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brand searched\n",
      "name searched\n",
      "description searched\n",
      "brand_category searched\n",
      "brand_canonical_url searched\n",
      "details searched\n",
      "tsv searched\n"
     ]
    }
   ],
   "source": [
    "# Regex for capturing women related words \n",
    "woman_exp = \"\\bwi(?:fe|ves)|girls?|wom(?:a|e)n|lad(?:y|ies)|madams?|brides?|widows?|females?|femini\\w*|maternal\\w*|moms?\\b\"\n",
    "\n",
    "# Search all columns\n",
    "for col in cols:\n",
    "    prod_df[f\"is_womens_clothing_{col}\"] = False\n",
    "    \n",
    "    # Find if women related words exist in the column\n",
    "    prod_df[f\"is_womens_clothing_{col}\"] = prod_df[col].str.contains(woman_exp, case=False, flags=re.IGNORECASE, regex=True)\n",
    "        \n",
    "    print(f\"{col} searched\")\n",
    "    \n",
    "# If any of is_womens_clothing is True, then is_womens_clothing is True. Otherwise False\n",
    "prod_df[f\"is_womens_clothing\"] = prod_df.iloc[:, 7:].any(axis=1)\n",
    "\n",
    "# Drop other intermediate columns\n",
    "col_to_drop = prod_df.iloc[0, 7:-1].index.to_list()\n",
    "prod_df.drop(col_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## product_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom in brand searched\n",
      "Bottom in name searched\n",
      "Bottom in description searched\n",
      "Bottom in brand_category searched\n",
      "Bottom in brand_canonical_url searched\n",
      "Bottom in details searched\n",
      "Bottom in tsv searched\n",
      "One_Piece in brand searched\n",
      "One_Piece in name searched\n",
      "One_Piece in description searched\n",
      "One_Piece in brand_category searched\n",
      "One_Piece in brand_canonical_url searched\n",
      "One_Piece in details searched\n",
      "One_Piece in tsv searched\n",
      "Shoe in brand searched\n",
      "Shoe in name searched\n",
      "Shoe in description searched\n",
      "Shoe in brand_category searched\n",
      "Shoe in brand_canonical_url searched\n",
      "Shoe in details searched\n",
      "Shoe in tsv searched\n",
      "Handbag in brand searched\n",
      "Handbag in name searched\n",
      "Handbag in description searched\n",
      "Handbag in brand_category searched\n",
      "Handbag in brand_canonical_url searched\n",
      "Handbag in details searched\n",
      "Handbag in tsv searched\n",
      "Scarf in brand searched\n",
      "Scarf in name searched\n",
      "Scarf in description searched\n",
      "Scarf in brand_category searched\n",
      "Scarf in brand_canonical_url searched\n",
      "Scarf in details searched\n",
      "Scarf in tsv searched\n"
     ]
    }
   ],
   "source": [
    "# Expressions\n",
    "bottom_exp = \"(?:baggies|bottom|pant|jean|cord|chino|denim|legging|overall|short|trouser)(?:es|s)?\"\n",
    "one_piece_exp = \"\\bone[\\S|\\s]?piece|\\w*dress|all[\\S|\\s]?in[\\S|\\s]?one\\b\"\n",
    "shoe_exp = \"(?:shoe|boot|cleat|hopper|trainer|flat|flip[\\S|\\s]?flop|heel|pump|slide|slipper|skate|sneaker|wedge)(?:s|es)?\"\n",
    "handbag_exp = \"(?:\\w* ?bags?|clutch(?:es)?|satchels?)\"\n",
    "scarf_exp = \"(?:\\w* ?scar(?:f|(?:ves))?|snoods?|stoles?|boas?|sarongs?)\"\n",
    "\n",
    "cats_list = [\"Bottom\", \"One_Piece\", \"Shoe\", \"Handbag\", \"Scarf\"]\n",
    "exps_list = [bottom_exp, one_piece_exp, shoe_exp, handbag_exp, scarf_exp]\n",
    "\n",
    "# For each product category\n",
    "for cat, exp in zip(cats_list, exps_list):\n",
    "    prod_df.loc[:,cat] = 0\n",
    "    \n",
    "    for col in cols:\n",
    "        # Add the number of occurrences in all columns\n",
    "        prod_df[cat] = prod_df[col].str.findall(exp, flags=re.IGNORECASE).apply(lambda x: len(x))\n",
    "        print(f\"{cat} in {col} searched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the category that has the highest score\n",
    "prod_df[\"product_category\"] = prod_df.iloc[:, 8:].apply(lambda x: x.idxmax() if x.sum() != 0 else None, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acknowledgement: idxmax fails to identify the category when there is a tie. idxmax fails to break the tie as it chooses the index of former tie. For example, if both shoe and handbag show up once in a product, it idxmax will choose shoe instead of handbag, which may not be true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_df.drop([\"Bottom\", \"One_Piece\", \"Shoe\", \"Handbag\", \"Scarf\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>tsv</th>\n",
       "      <th>is_womens_clothing</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fila</td>\n",
       "      <td>original fitness sneakers</td>\n",
       "      <td>vintage fitness leather sneakers with logo pri...</td>\n",
       "      <td>themensstore/shoes/sneakers/lowtop</td>\n",
       "      <td>https://www.saksfifthavenue.com/fila-original-...</td>\n",
       "      <td>leather/synthetic upper\\nlace-up closure\\ntext...</td>\n",
       "      <td>'design':12 'fila':1a 'fit':3a,6 'leather':7 '...</td>\n",
       "      <td>False</td>\n",
       "      <td>Shoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chanel</td>\n",
       "      <td>hat</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://www.saksfifthavenue.com/chanel-hat/pro...</td>\n",
       "      <td>wool tweed &amp; felt</td>\n",
       "      <td>'chanel':1a 'hat':2a</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame</td>\n",
       "      <td>petit oval buckle belt</td>\n",
       "      <td>a timeless leather belt crafted from smooth co...</td>\n",
       "      <td>accessories</td>\n",
       "      <td>https://frame-store.com/products/petit-oval-bu...</td>\n",
       "      <td></td>\n",
       "      <td>'belt':5a,9 'buckl':4a,21 'cowhid':13 'craft':...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    brand                       name  \\\n",
       "0    fila  original fitness sneakers   \n",
       "1  chanel                        hat   \n",
       "2   frame     petit oval buckle belt   \n",
       "\n",
       "                                         description  \\\n",
       "0  vintage fitness leather sneakers with logo pri...   \n",
       "1                                                      \n",
       "2  a timeless leather belt crafted from smooth co...   \n",
       "\n",
       "                       brand_category  \\\n",
       "0  themensstore/shoes/sneakers/lowtop   \n",
       "1                             unknown   \n",
       "2                         accessories   \n",
       "\n",
       "                                 brand_canonical_url  \\\n",
       "0  https://www.saksfifthavenue.com/fila-original-...   \n",
       "1  https://www.saksfifthavenue.com/chanel-hat/pro...   \n",
       "2  https://frame-store.com/products/petit-oval-bu...   \n",
       "\n",
       "                                             details  \\\n",
       "0  leather/synthetic upper\\nlace-up closure\\ntext...   \n",
       "1                                  wool tweed & felt   \n",
       "2                                                      \n",
       "\n",
       "                                                 tsv  is_womens_clothing  \\\n",
       "0  'design':12 'fila':1a 'fit':3a,6 'leather':7 '...               False   \n",
       "1                               'chanel':1a 'hat':2a               False   \n",
       "2  'belt':5a,9 'buckl':4a,21 'cowhid':13 'craft':...               False   \n",
       "\n",
       "  product_category  \n",
       "0             Shoe  \n",
       "1             None  \n",
       "2             None  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brand searched\n",
      "name searched\n",
      "description searched\n",
      "brand_category searched\n",
      "brand_canonical_url searched\n",
      "details searched\n",
      "tsv searched\n"
     ]
    }
   ],
   "source": [
    "color_exp = \"(?:Beige|Black|Blue|Brown|Burgund(?:y|ies)|Gold|Gra(?:y|ies)|Green|Multi|Nav(?:y|ies)|Neutral|Orange|Pink|Purple|Red|Silver|Teal|White|Yellow)s?\"\n",
    "\n",
    "for col in cols:\n",
    "    prod_df[f\"colors_{col}\"] = None\n",
    "    \n",
    "    # Find colors\n",
    "    prod_df[f\"colors_{col}\"] = prod_df[col].str.findall(color_exp, flags=re.IGNORECASE).apply(lambda x: ''.join(x))\n",
    "        \n",
    "    print(f\"{col} searched\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append colors to the list\n",
    "prod_df[\"colors\"] = prod_df.iloc[:, 9:].apply(lambda x: list(set([color for color in x if color != ''])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "prod_df.drop([\"colors_brand\", \"colors_name\", \"colors_description\", \"colors_brand_category\",\n",
    "              \"colors_brand_canonical_url\", \"colors_details\", \"colors_tsv\"],\n",
    "             axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change color to \"Multi\" if multiple colors in a product\n",
    "prod_df[\"colors\"] = prod_df[\"colors\"].apply(lambda x: x if len(x) < 2 else [\"Multi\"])\n",
    "prod_df[\"colors\"] = prod_df[\"colors\"].apply(lambda x: None if len(x) == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>brand_canonical_url</th>\n",
       "      <th>details</th>\n",
       "      <th>tsv</th>\n",
       "      <th>is_womens_clothing</th>\n",
       "      <th>product_category</th>\n",
       "      <th>colors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fila</td>\n",
       "      <td>original fitness sneakers</td>\n",
       "      <td>vintage fitness leather sneakers with logo pri...</td>\n",
       "      <td>themensstore/shoes/sneakers/lowtop</td>\n",
       "      <td>https://www.saksfifthavenue.com/fila-original-...</td>\n",
       "      <td>leather/synthetic upper\\nlace-up closure\\ntext...</td>\n",
       "      <td>'design':12 'fila':1a 'fit':3a,6 'leather':7 '...</td>\n",
       "      <td>False</td>\n",
       "      <td>Shoe</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chanel</td>\n",
       "      <td>hat</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://www.saksfifthavenue.com/chanel-hat/pro...</td>\n",
       "      <td>wool tweed &amp; felt</td>\n",
       "      <td>'chanel':1a 'hat':2a</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame</td>\n",
       "      <td>petit oval buckle belt</td>\n",
       "      <td>a timeless leather belt crafted from smooth co...</td>\n",
       "      <td>accessories</td>\n",
       "      <td>https://frame-store.com/products/petit-oval-bu...</td>\n",
       "      <td></td>\n",
       "      <td>'belt':5a,9 'buckl':4a,21 'cowhid':13 'craft':...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[Multi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lilly pulitzer kids</td>\n",
       "      <td>little gir's &amp; girl's ariana one-piece upf 50+...</td>\n",
       "      <td>pretty ruffle sleeves and trim elevate essenti...</td>\n",
       "      <td>justkids/girls214/girls/swimwearcoverups,justk...</td>\n",
       "      <td>https://www.saksfifthavenue.com/lilly-pulitzer...</td>\n",
       "      <td>scoopneck\\nadjustable straps\\nflutter sleeves\\...</td>\n",
       "      <td>'50':14a 'allov':28 'ariana':9a 'color':27 'el...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kissy kissy</td>\n",
       "      <td>baby girl's endearing elephants pima cotton co...</td>\n",
       "      <td>versatile convertible gown with elephant applique</td>\n",
       "      <td>justkids/baby024months/infantgirls/footiesrompers</td>\n",
       "      <td>https://www.saksfifthavenue.com/kissy-kissy-ba...</td>\n",
       "      <td>v-neckline\\nlong sleeves\\nfront snap closure\\n...</td>\n",
       "      <td>'appliqu':17 'babi':3a 'convert':10a,13 'cotto...</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42368</th>\n",
       "      <td>mara hoffman</td>\n",
       "      <td>atlas oversized belted mÃ©lange wool coat</td>\n",
       "      <td>mÃ©lange beige and cream wool button fastenings...</td>\n",
       "      <td>clothing / coats / long</td>\n",
       "      <td>https://www.net-a-porter.com/us/en/product/117...</td>\n",
       "      <td>fits true to size, take your normal size \\ndes...</td>\n",
       "      <td>'100':21 'atlas':3a 'beig':10 'belt':5a 'breas...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[beige]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42369</th>\n",
       "      <td>philosophy di lorenzo serafini</td>\n",
       "      <td>cropped crochet-trimmed georgette top</td>\n",
       "      <td>cream georgette ties at neck, concealed hook f...</td>\n",
       "      <td>clothing / tops / blouses</td>\n",
       "      <td>https://www.net-a-porter.com/us/en/product/111...</td>\n",
       "      <td>fits true to size, take your normal size \\nint...</td>\n",
       "      <td>'100':21 'back':20 'conceal':16 'cream':11 'cr...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42370</th>\n",
       "      <td>vanessa bruno</td>\n",
       "      <td>juna cotton-corduroy mini skirt</td>\n",
       "      <td>sand cotton-corduroy concealed hook and zip fa...</td>\n",
       "      <td>clothing / skirts / mini</td>\n",
       "      <td>https://www.net-a-porter.com/us/en/product/116...</td>\n",
       "      <td>fits true to size, take your normal size \\ntho...</td>\n",
       "      <td>'100':20 '35':25 '65':23 'acet':24 'back':19 '...</td>\n",
       "      <td>False</td>\n",
       "      <td>Bottom</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42371</th>\n",
       "      <td>eve denim</td>\n",
       "      <td>annabel rigid mid-rise skinny jean</td>\n",
       "      <td>although mom jeans and boyfriend jeans are all...</td>\n",
       "      <td>women:clothing:jeans</td>\n",
       "      <td>https://pink.modaoperandi.com/eve-denim-r20/an...</td>\n",
       "      <td>button and zip fastening \\ncomposition: 98% co...</td>\n",
       "      <td>'add':36 'although':10 'annabel':3a,40 'boyfri...</td>\n",
       "      <td>True</td>\n",
       "      <td>Bottom</td>\n",
       "      <td>[pink]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42372</th>\n",
       "      <td>fila</td>\n",
       "      <td>kessler colorblock track jacket</td>\n",
       "      <td>only at saks. ultra-sporty nylon track jacket ...</td>\n",
       "      <td>themensstore/apparel/outerwear/lightweightjackets</td>\n",
       "      <td>https://www.saksfifthavenue.com/fila-kessler-c...</td>\n",
       "      <td>attached drawstring hood\\nstand collar\\nlong s...</td>\n",
       "      <td>'colorblock':3a 'detail':18 'fila':1a 'jacket'...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42373 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                brand  \\\n",
       "0                                fila   \n",
       "1                              chanel   \n",
       "2                               frame   \n",
       "3                 lilly pulitzer kids   \n",
       "4                         kissy kissy   \n",
       "...                               ...   \n",
       "42368                    mara hoffman   \n",
       "42369  philosophy di lorenzo serafini   \n",
       "42370                   vanessa bruno   \n",
       "42371                       eve denim   \n",
       "42372                            fila   \n",
       "\n",
       "                                                    name  \\\n",
       "0                              original fitness sneakers   \n",
       "1                                                    hat   \n",
       "2                                 petit oval buckle belt   \n",
       "3      little gir's & girl's ariana one-piece upf 50+...   \n",
       "4      baby girl's endearing elephants pima cotton co...   \n",
       "...                                                  ...   \n",
       "42368           atlas oversized belted mÃ©lange wool coat   \n",
       "42369              cropped crochet-trimmed georgette top   \n",
       "42370                    juna cotton-corduroy mini skirt   \n",
       "42371                 annabel rigid mid-rise skinny jean   \n",
       "42372                    kessler colorblock track jacket   \n",
       "\n",
       "                                             description  \\\n",
       "0      vintage fitness leather sneakers with logo pri...   \n",
       "1                                                          \n",
       "2      a timeless leather belt crafted from smooth co...   \n",
       "3      pretty ruffle sleeves and trim elevate essenti...   \n",
       "4      versatile convertible gown with elephant applique   \n",
       "...                                                  ...   \n",
       "42368  mÃ©lange beige and cream wool button fastenings...   \n",
       "42369  cream georgette ties at neck, concealed hook f...   \n",
       "42370  sand cotton-corduroy concealed hook and zip fa...   \n",
       "42371  although mom jeans and boyfriend jeans are all...   \n",
       "42372  only at saks. ultra-sporty nylon track jacket ...   \n",
       "\n",
       "                                          brand_category  \\\n",
       "0                     themensstore/shoes/sneakers/lowtop   \n",
       "1                                                unknown   \n",
       "2                                            accessories   \n",
       "3      justkids/girls214/girls/swimwearcoverups,justk...   \n",
       "4      justkids/baby024months/infantgirls/footiesrompers   \n",
       "...                                                  ...   \n",
       "42368                            clothing / coats / long   \n",
       "42369                          clothing / tops / blouses   \n",
       "42370                           clothing / skirts / mini   \n",
       "42371                               women:clothing:jeans   \n",
       "42372  themensstore/apparel/outerwear/lightweightjackets   \n",
       "\n",
       "                                     brand_canonical_url  \\\n",
       "0      https://www.saksfifthavenue.com/fila-original-...   \n",
       "1      https://www.saksfifthavenue.com/chanel-hat/pro...   \n",
       "2      https://frame-store.com/products/petit-oval-bu...   \n",
       "3      https://www.saksfifthavenue.com/lilly-pulitzer...   \n",
       "4      https://www.saksfifthavenue.com/kissy-kissy-ba...   \n",
       "...                                                  ...   \n",
       "42368  https://www.net-a-porter.com/us/en/product/117...   \n",
       "42369  https://www.net-a-porter.com/us/en/product/111...   \n",
       "42370  https://www.net-a-porter.com/us/en/product/116...   \n",
       "42371  https://pink.modaoperandi.com/eve-denim-r20/an...   \n",
       "42372  https://www.saksfifthavenue.com/fila-kessler-c...   \n",
       "\n",
       "                                                 details  \\\n",
       "0      leather/synthetic upper\\nlace-up closure\\ntext...   \n",
       "1                                      wool tweed & felt   \n",
       "2                                                          \n",
       "3      scoopneck\\nadjustable straps\\nflutter sleeves\\...   \n",
       "4      v-neckline\\nlong sleeves\\nfront snap closure\\n...   \n",
       "...                                                  ...   \n",
       "42368  fits true to size, take your normal size \\ndes...   \n",
       "42369  fits true to size, take your normal size \\nint...   \n",
       "42370  fits true to size, take your normal size \\ntho...   \n",
       "42371  button and zip fastening \\ncomposition: 98% co...   \n",
       "42372  attached drawstring hood\\nstand collar\\nlong s...   \n",
       "\n",
       "                                                     tsv  is_womens_clothing  \\\n",
       "0      'design':12 'fila':1a 'fit':3a,6 'leather':7 '...               False   \n",
       "1                                   'chanel':1a 'hat':2a               False   \n",
       "2      'belt':5a,9 'buckl':4a,21 'cowhid':13 'craft':...               False   \n",
       "3      '50':14a 'allov':28 'ariana':9a 'color':27 'el...                True   \n",
       "4      'appliqu':17 'babi':3a 'convert':10a,13 'cotto...                True   \n",
       "...                                                  ...                 ...   \n",
       "42368  '100':21 'atlas':3a 'beig':10 'belt':5a 'breas...               False   \n",
       "42369  '100':21 'back':20 'conceal':16 'cream':11 'cr...               False   \n",
       "42370  '100':20 '35':25 '65':23 'acet':24 'back':19 '...               False   \n",
       "42371  'add':36 'although':10 'annabel':3a,40 'boyfri...                True   \n",
       "42372  'colorblock':3a 'detail':18 'fila':1a 'jacket'...               False   \n",
       "\n",
       "      product_category   colors  \n",
       "0                 Shoe     None  \n",
       "1                 None     None  \n",
       "2                 None  [Multi]  \n",
       "3                 None     None  \n",
       "4                 None     None  \n",
       "...                ...      ...  \n",
       "42368             None  [beige]  \n",
       "42369             None     None  \n",
       "42370           Bottom     None  \n",
       "42371           Bottom   [pink]  \n",
       "42372             None     None  \n",
       "\n",
       "[42373 rows x 10 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
